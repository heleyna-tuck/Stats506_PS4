---
title: "Stats506_PS4"
author: "Heleyna Tucker"
format:
  html:
    embed-resources: true
editor: visual
---

# Problem 1 - Tidyverse

I will use the tidyverse for this problem. In particular, I will use piping and dplyr as much as I am able.

Install and load the nycflights13, tidyverse, and dplyr packages below:

```{r}
library(tidyverse)
library(nycflights13)
library(dplyr)
```

### Part A: Generating summary tables for the data

Below I will generate a table (which can just be a nicely printed tibble) reporting the mean and median departure delay per airport. I will generate a second table (which can also be printed as a tibble) reporting the mean and median arrival delay per airport. Exclude any destination with under 10 flights. Do this exclusion through code, not manually.

Additionally, I will:

-   Order both tables in descending mean delay.

-   Both tables should use the airport *names* not the airport *codes*.

-   Both tables should print all rows.

Visualize the data below:

```{r}
head(airports)
head(flights)
head(planes)
```

Below, using tidyverse pipping techniques, I will first find the mean and median of dep_delay in the flights data set. I will then order the flights in descending mean order. Using left_join() I will access the name of the airports from the airports data set.

```{r}
dep_delays <- flights %>%
  group_by(origin) %>%
  summarize(
    mean_delay_dep = mean(dep_delay, na.rm = TRUE),
    median_delay_dep = median(dep_delay, na.rm = TRUE),
  ) %>%
  arrange(desc(mean_delay_dep)) %>%
  left_join(airports, by = c("origin" = "faa")) %>%
  select(name, mean_delay_dep, median_delay_dep)
print(dep_delays)
```

Below I use the same technique as above to order and find the mean and median for the arrival airport. I will also exclude any destination that has under 10 flights using a count variable and filter() to filter out any flights who have a flight count less than or equal to 10:

```{r}
arrival_delays <- flights %>%
  group_by(dest) %>%
  summarize(
    mean_delay_arr = mean(dep_delay, na.rm = TRUE),
    median_delay_arr = median(dep_delay, na.rm = TRUE),
    count = n()
  ) %>%
  filter(count >= 10) %>%
  arrange(desc(mean_delay_arr)) %>%
  left_join(airports, by = c("dest" = "faa")) %>%
  select(name, mean_delay_arr, median_delay_arr)
print(arrival_delays)
```

### Part B: How many flights did the aircraft model with the fastest average speed take?

Below I will answer the question and produce a tibble with 1 row, and entries for the model, average speed (in MPH) and number of flights.

First, I will calculate the average speed in MPH for each aircraft below and make a new variable flights_speed with these averages:

Because I need to access the model of each plane, I will use a left_join to join the flights and planes data with the tailnum variable, group by the model and calculate the average distance for each model and the number of flights each model has. This is shown below:

```{r}
flights_speed <- flights %>%
  left_join(planes, by = "tailnum") %>%
  group_by(model) %>%
  summarize(avg_speed_mph = sum(distance)/ sum(air_time), 
            n_flights = n()) %>%
  arrange(desc(avg_speed_mph))
```

Get the aircraft with the fastest average speed:

```{r}
fastest <- flights_speed[1,]
fastest
```

Above we can see that the plane with the fastest average flights speed is model 777-222 and it has 4 total flights.

# Problem 2 - get_temp()

For this problem, I will use the tidyverse. In particular, I will use piping and dplyr as much as I am able.

Below I will load the Chicago NNMAPS data we used in the visualization lectures. I will write a function get_temp() that allows a user to request the average temperature for a given month. The arguments should be:

-   month: Month, either a numeric 1-12 or a string.

-   year: A numeric year.

-   data: the data set to obtain data from.

-   celsius: logically indicating whether the results should be in Celsius. Default FALSE.

-   average_fn: A function with which to compute the mean. Default is mean.

The output should be a numeric vector of length 1. The code inside the function should, as with the rest of this problem, use the tidyverse. Be sure to sanitize the input.

load in the Chicago NMMAPS data below from the dlnm library. Visualize data:

```{r}
nnmaps <- read_csv('/Users/19892/OneDrive/Documents/STATS506/ProblemSets/Stats506_PS4/chicago-nmmaps.csv')
head(nnmaps)
```

I will the write the get_temp() function below. One thing to not is that I changed month and year to month_in and year_in so there is no overlap with the initial dataset variable names. This was indicated by the professor to be okay:

```{r}
#' Function to calculate the average temperature over a given year and month in a dataset.
#'
#' @param month_in Input month. Can give a numeric 1-12, full length month name or abriviated 3 character month.
#' @param year_in Input year. Can only be from 1997-2000 (The max and min year of the dataset)
#' @param data input dataset, in this case it is nnmaps
#' @param celsius boolean to say whether the user wants the result output to be in fahrenheit (FALSE) or celsius (TRUE)
#' @param average_fn average function to use indicated by user but mean function is used by default
#'
#' @return result - average temperature
#' @export
#'
#' @examples
get_temp <- function(month_in, year_in, data, celsius = FALSE, average_fn = mean){
  
  # Validate and sanitize the input
  if (!is.numeric(year_in) || !year_in %in% data$year){
    stop("Invalid year. Please provide a numeric year between 1997 and 2000.")
  }
  if (is.character(month_in) && !substr(tolower(month_in),1,3) %in% substr(tolower(month.name), 1, 3)){
    stop("Invalid month. Please provide a valid numeric value (1-12) or a month name.")
  }
  else if (!is.character(month_in) && !month_in %in% 1:12){
        stop("Invalid month. Please provide a valid numeric value (1-12) or a month name.")
  }
  
  #Convert months inputed as a string to a numeric:
  if(is.character(month_in) && substr(tolower(month_in),1,3) %in% substr(tolower(month.name), 1, 3)){
    month_in <- as.numeric(match(substr(tolower(month_in),1,3), substr(tolower(month.name), 1, 3)))
  }
  
 # Filter the data for the specified year and month
  result <- data %>%
    filter(year == year_in, month_numeric == month_in) %>%
    select(temp) %>%
    pull() %>%
    average_fn()
  
  # Convert to Celsius if necessary
  if (celsius) {
    result <- (result - 32) * 5/9
  }
  
  return(result)
}
```

Test the function below. As we can see, it is working as we would expect:

```{r}
get_temp("Apr", 1999, data = nnmaps)
```

```{r}
get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
```

```{r}
get_temp(10, 1998, data = nnmaps, average_fn = median)
```

```{r}
get_temp(13, 1998, data = nnmaps)
```

```{r}
get_temp(2, 2005, data = nnmaps)
```

```{r}
get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         })
```

# Problem 3 - SAS

This problem will be done entirely within SAS.

Access the RECS 2020 data and download a copy of the data. Load or import the data into SAS. I will answer the following questions:

### Part A: What state has the highest percentage of records?

What state has the highest percentage of records? What percentage of all records correspond to Michigan? (Don't forget to account for the sampling weights!)

The code that I used for this question can be found below:

```         
/* data libraries for reading/writing data: -------------------------------- */
%let in_path = ~/sasuser.v94/input_data;
%let out_path = ~/sasuser.v94/output_data; 
libname in_lib "&in_path."; 
libname out_lib "&out_path.";

data recs; 
 set in_lib.recs2020_public_v5;

proc freq data = recs;
	TABLES state_name / OUT = StateFreq;
	WEIGHT NWEIGHT;
RUN;

proc sort data = StateFreq;
	BY DESCENDING COUNT;
RUN;

DATA MichiganPercentage;
	SET StateFreq;
	WHERE state_name = 'Michigan';
RUN;
```

Above loads in the data as recs, then gets the frequency of the state records, taking into account the weight of NWEIGHT. Then, proc sort sorts the data into descending order by the count/frequency of records to obtain the highest percentage of records. This was found to be California The next code block finds the percentage corresponding to Michigan (you could look at the original frequency table and find Michigan). This was found to be about 3.17%

### Part B: Generate histogram (total electricity cost)

Generate a histogram of the total electricity cost in dollars, amongst those with a strictly positive cost.

Below is the code I used for this part, using the variable DOLLAREL for the total electricity cost in dollars. I used the WHERE command to get all the strictly positive values.

```         
PROC SGPLOT DATA=recs;
   HISTOGRAM DOLLAREL / 
      FILLATTRMAP=GraphDataAttrMap;
   WHERE DOLLAREL > 0; /* Filter for strictly positive costs */
   XAXIS LABEL="Total Electricity Cost (Dollars)";
   YAXIS LABEL="Frequency";
RUN;
```

When we run the above code, we can see from the histogram that around 1,000 dollars tends to be the most frequent total electricity cost.

### Part C: Histogram (log total electricity cost)

Generate a histogram of the log of the total electricity cost. Below I will first make a new variable called LogTotalElectricityCost that takes the log of the total electricity cost of the recs data. Then, I will write the same code as in part B to make the histogram

```         
DATA recs;
    SET recs;
    LogTotalElectricityCost = log(DOLLAREL);
RUN;

/* Create a histogram of the log of the total electricity cost */
PROC SGPLOT DATA=recs;
    HISTOGRAM LogTotalElectricityCost / 
        FILLATTRMAP=GraphDataAttrMap;
    WHERE LogTotalElectricityCost > 0; /* Filter for strictly positive log costs */
    XAXIS LABEL="Log of Total Electricity Cost";
    YAXIS LABEL="Frequency";
RUN;
```

The output of this part showed that around 7.5 was the most frequent log of total electricity cost.

### Part D: Fit a linear regression model

Fit a linear regression model predicting the log of the total electricity cost based upon the number of rooms in the hose and whether or not the house has a garage. (Don't forget weights)

```         
```

### Part E: Predicted values and scatterplot

Use the model to generate predicted values and create a scatterplot of predicted total electricity cost vs. actual total electricity cost (not on the log scale).

```         
```

# Problem 4 - Multiple tools
